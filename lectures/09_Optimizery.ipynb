{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oznaczenia\n",
    "\n",
    "* $\\theta$ - wektor wszystkich parametrów modelu\n",
    "* $\\theta^{(0)}$ - początkowa wartość parametrów\n",
    "* $\\theta^{(t)}$ - wartość parametrów po $t$ krokach (po czasie $t$)\n",
    "\n",
    "\n",
    "* $\\Delta\\theta^{(t)} := \\theta^{(t+1)} - \\theta^{(t)}$ - krok w czasie $t$\n",
    "\n",
    "\n",
    "* $L$ - różniczkowalna funkcja kosztu\n",
    "\n",
    "\n",
    "* $\\eta$ - __learning rate__\n",
    "    * kontroluje szybkość uczenia\n",
    "    * obecna w praktycznie każdym optimizerze\n",
    "\n",
    "Wartość $L$ zależy od:\n",
    "* wektora $\\theta$\n",
    "* danych treningowych\n",
    "* być może jeszcze innych stałych\n",
    "\n",
    "Optymalizujemy tylko $\\theta$, będziemy pisać w skrócie $L(\\theta)$.\n",
    "\n",
    "$L$ zwraca liczbę. Zakładamy, że umiemy policzyć gradient $\\nabla L(\\theta)$.\n",
    "\n",
    "__Gradientowa__ i __iteracyjna__ minimalizacja $L$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Materiały dodatkowe\n",
    "\n",
    "http://ruder.io/optimizing-gradient-descent/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metody"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent\n",
    "\n",
    "#### Parametry\n",
    "* $\\eta$ - learning rate (typowe wartości: od 0.001 do 0.01)\n",
    "\n",
    "#### Update\n",
    "\n",
    "1. $\\theta^{(t+1)}=\\theta^{(t)} - \\eta\\nabla L(\\theta^{(t)})$\n",
    "\n",
    "#### Dyskusja\n",
    "\n",
    "<img src=\"../ml_figures/Optimizery_steepest_descent.png\" width=70%>\n",
    "\n",
    "1. $- \\nabla L(\\theta^{(t)}$ to kierunek najszybszego spadku $L$\n",
    "2. ale $- \\nabla L(\\theta^{(t)}$ __nie wskazuje__ w kierunku optymalnego $\\theta$\n",
    "3. wektor gradientu $\\nabla L(\\theta^{(t)})$ jest prostopadły do hiperpłaszczyzny stycznej do powierzchni o równych wartościch funkcji kosztu (_isosurface_) w miejscu $\\theta^{(t)}$\n",
    "4. zmniejszenie $L$ odpowiada __co najmniej__ rozwartemu kątowi między $\\nabla\\theta^{(t)}$ a $\\Delta\\theta^{(t)}$\n",
    "5. __zbyt duże__ $\\eta \\|\\Delta\\theta^{(t)}\\|$ spowoduje, że $\\theta^{(t+1)}$ może znaleźć się po _drugiej stronie krzywizny_\n",
    "6. learning rate\n",
    "    * mała wartość - spowalnia uczenie\n",
    "    * duża wartość - powoduje __oscylacje__, problem ze zbieżnością\n",
    "7. dlaczego nie normalizujemy $\\nabla L(\\theta^{(t)})$?\n",
    "    * duża wartość gradientu to __duża lokalna zmienność $L$__ - powinniśmy robić __małe kroki__ (precyzyjne)\n",
    "    * mała wartość gradientu to __mała lokalna zmienność $L$__ - powinniśmy robić __duże kroki__ (żeby szybciej opuścić __plateau__)\n",
    "\n",
    "7. wariant GD ze zmiennym w czasie $\\eta$\n",
    "  * malejący w stosunku odwrotnym do kroku uczenia $t$\n",
    "    * warunki konieczne osiągnięcia optymalnego $\\theta$ (przy jakich założeniach? uwaga na __lokalne minima__)\n",
    "        $$\\begin{align}\\sum_t\\eta_t^2\\lt\\infty\\\\\\sum_t\\eta_t=\\infty\\end{align}$$\n",
    "    * $v_0(1-\\lambda\\eta_0)^t$ dla poczętkowego $\\eta_0$ i stałej $\\lambda$\n",
    "    * $\\exp(-t/\\tau)$ dla stałej $\\tau$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Momentum\n",
    "\n",
    "#### Parametry\n",
    "* $\\eta$ - learning rate (typowe wartości: od 0.001 do 0.01)\n",
    "* $\\gamma$ - zawsze $<1$, zwykle równe 0.9.\n",
    "\n",
    "#### Parametry wewnętrzne\n",
    "* $v^{(t)}$ - wektor __pędu__ (_momentum_) w czasie $t$, wymiar taki sam jak $\\theta$\n",
    "\n",
    "#### Inicjalizacja\n",
    "\n",
    "$v^{(0)} = \\mathbf{0}$\n",
    "\n",
    "#### Update\n",
    "\n",
    "1. $v^{(t+1)} = \\gamma v^{(t)} + \\eta\\nabla L(\\theta^{(t)})$\n",
    "2. $\\theta^{(t+1)}=\\theta^{(t)} - v^{(t+1)}$\n",
    "\n",
    "#### Dyskusja\n",
    "\n",
    "1. Analogia do kulki toczącej się ze wzgórza, $\\gamma$ to tarcie lub opór powietrza.\n",
    "2. __Pamięć__\n",
    "    * wzajemnie wzmacniają się kroki w __istotnym kierunku__\n",
    "    * __oscylacje__ uśredniają się do małej wartości\n",
    "    * mniejsze spowolnienie na __plateau__, jeśli \"kulka\" była rozpędzona"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nesterov accelerated gradient NAG\n",
    "\n",
    "#### Parametry\n",
    "* $\\eta$ - learning rate (typowe wartości: od 0.001 do 0.01)\n",
    "* $\\gamma$ - zawsze $<1$, zwykle równe 0.9.\n",
    "\n",
    "#### Parametry wewnętrzne\n",
    "* $v^{(t)}$ - wektor __pędu__ (_momentum_) w czasie $t$, wymiar taki sam jak $\\theta$\n",
    "\n",
    "#### Inicjalizacja\n",
    "\n",
    "$v^{(0)} = \\mathbf{0}$\n",
    "\n",
    "#### Update\n",
    "\n",
    "1. $v^{(t+1)} = \\gamma v^{(t)} + \\eta\\nabla L(\\theta^{(t)}-\\gamma v^{(t)})$\n",
    "2. $\\theta^{(t+1)}=\\theta^{(t)} - v^{(t+1)}$\n",
    "\n",
    "#### Dyskusja\n",
    "\n",
    "1. __spojrzenie wprzód__\n",
    "    * zgrubne oszacowanie _prawdopodobnego_ nowego $\\theta^{(t+1)}=\\theta^{(t)}-\\gamma v^{(t)}$\n",
    "    * gradient liczony w nowym miejscu\n",
    "    * rozszerzenie momentum z _ekstrapolacją_\n",
    "    \n",
    "2. __parametry__\n",
    "    * learning rate ustalony\n",
    "        * ewentualne modyfikacje w eksperymentach\n",
    "    * __momentum nesterova__\n",
    "        * schemat: $\\gamma^{(t)}=1-3/(5+t)$\n",
    "        * rosnące\n",
    "        * w dalszych iteracjach dalej wybiega wprzód"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
