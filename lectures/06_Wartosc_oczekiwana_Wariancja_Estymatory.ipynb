{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wartość oczekiwana\n",
    "\n",
    "Wartość oczekiwana zmiennej losowej $X$ to \"średnia wartość\", jaką przyjmuje ta zmienna. Chodzi nam o średnią ważoną, gdzie wagi to prawdopodobieństwa zadane przez $X$.\n",
    "\n",
    "Przypominam, że indeks górny __nie oznacza tu potęgowania__, ale kolejne wartości zmiennej $X$.\n",
    "\n",
    "Jeśli rozkład $X$ jest dyskretny na zbiorze $\\{x^1, x^2, \\ldots x^K\\}$, to wartość oczekiwana zdefiniowana jest jako\n",
    "\n",
    "$$\\mathbb{E}X := p(X=x^1)\\cdot x^1 + \\ldots + p(X=x^K)\\cdot x^K = \\sum_{k=1}^K p(X=x^k)\\cdot x^k$$\n",
    "\n",
    "Jeśli zbiór wartości $X$ jest nieskończony, to mamy\n",
    "\n",
    "$$\\mathbb{E}X := \\sum_{k=1}^\\infty p(X=x^k)\\cdot x^k$$\n",
    "\n",
    "W wypadku zmiennej ciągłej suma zamienia się na całkę, a prawdopodobieństwo $p$ na gęstość rozkładu $f$\n",
    "\n",
    "$$\\mathbb{E}X := \\int_{\\mathbb{R}} f(x)\\cdot x\\, dx$$\n",
    "\n",
    "Wartość oczekiwana to __nie__ jest wartość, która pojawia się najczęściej. Jeśli np. $X$ opisuje rzut symetryczną sześcienną kostką, to wartość oczekiwana wynosi $\\mathbb{E}X = 3,5$ - taka wartość nigdy nie zostanie wylosowana.\n",
    "\n",
    "W wypadku zmiennej wielowymiarowej jest to \"średni wektor\", którego współrzędne to wartości oczekiwane współrzędnych. Suma zamienia się na sumę wektorów, całka na całkę wielowymiarową.\n",
    "\n",
    "Proszę mieć na uwadze, że $X$ to __zmienna losowa__, ale $\\mathbb{E}X$ to po prostu __liczba__ (lub wektor).\n",
    "\n",
    "Istnieją zmienne losowe, które nie mają wartości oczekiwanej (suma nieskończona jest rozbieżna, funkcja $f(x)\\cdot x$ nie jest całkowalna)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Warunkowa wartość oczekiwana\n",
    "\n",
    "Jeśli mamy dwie zmienne losowe $X, Y$, to możemy zapytać o wartość oczekiwaną $X$, jeśli $Y$ jest ustalone i np. równe $a$. Niech $p(x,y)$ będzie rozkładem łącznym w przypadku dyskretnym, a $f(x,y)$ gęstością w przypadku ciągłym.\n",
    "\n",
    "$$\\mathbb{E}(X \\mid Y=a) := \\dfrac{\\sum_{k=1}^\\infty p(X=x^k, Y=a)\\cdot x^k}{p(Y=a)} = \\sum_{k=1}^\\infty p(X=x^k \\mid Y=a)\\cdot x^k$$\n",
    "\n",
    "$$\\mathbb{E}(X \\mid Y=a) := \\dfrac{\\int_{\\mathbb{R}} f(x,a)\\cdot x\\, dx}{\\int_{\\mathbb{R}} f(x,a)\\, dx}$$\n",
    "\n",
    "Jeśli zmienne są niezależne, to $\\mathbb{E}(X\\mid Y) = \\mathbb{E}X$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wariancja\n",
    "\n",
    "Wariancja zmiennej $X$ mówi nam, jak bardzo ta zmienna różni się od swojej wartości oczekiwanej. Im mniejsza wariancja, tym mniejsza ta różnica.\n",
    "\n",
    "Wariancja zmiennej $X$ to wartość oczekiwana zmiennej $(X-\\mathbb{E}X)^2$, czyli\n",
    "$$Var(X) := \\mathbb{E}((X - \\mathbb{E}X)^2)$$\n",
    "\n",
    "Co w powyższym wzorze jest zmienną losową, a co liczbą (wektorem)?\n",
    "\n",
    "Istnieją zmienne losowe, które nie mają wariancji."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estymatory\n",
    "\n",
    "Zakładamy, że istnieje pewien parametr, którego wartość jest ustalona, ale nieznana. Wartość tego parametru ma wpływ na dane, które obserwujemy. Chcemy _wyestymować_ ten parametr, korzystając z obserwacji.\n",
    "\n",
    "To, co różni estymowanie od podejścia bayesowkiego, to założenie, że chcemy otrzymać jedną konkretną wartość parametru. Nie chcemy modelować naszej niepewności na jego temat.\n",
    "\n",
    "Estymator parametru $\\theta$ to taka funkcja, która przyjmuje na wejściu $N$ obserwacji i zwraca estymowaną wartość $\\widehat\\theta$, która w jakimś sensie jest \"najlepszym przybliżeniem\" prawdziwej nieznanej wartości $\\theta$.\n",
    "\n",
    "Najlepiej zrozumieć koncepcję estymatora na przykładach.\n",
    "\n",
    "### Estymator wartości oczekiwanej\n",
    "\n",
    "Załóżmy, że $x^1, x^2, \\ldots, x^N$ to ciąg sampli z $X$. Niech\n",
    "\n",
    "$$ \\theta := \\mathbb{E}X $$\n",
    "\n",
    "Wtedy możemy zdefiniować estymator\n",
    "\n",
    "$$ \\widehat\\theta := \\dfrac{x^1 + x^2 + \\ldots + x^N}{N} $$\n",
    "\n",
    "Czyli twierdzimy, że średnia obserwacji dobrze przybliża wartość oczekiwaną $X$.\n",
    "\n",
    "### Estymatory wariancji\n",
    "\n",
    "Załóżmy, że $x^1, x^2, \\ldots, x^N$ to ciąg sampli z $X$. Niech\n",
    "\n",
    "$$ \\theta := Var(X) = \\mathbb{E}((X - \\mathbb{E}X)^2) $$\n",
    "\n",
    "Niech\n",
    "\n",
    "$$ S := \\dfrac{x^1 + x^2 + \\ldots + x^N}{N} $$\n",
    "\n",
    "Wtedy możemy zdefiniować tzw. __obciążony__ estymator wariancji\n",
    "\n",
    "$$ \\widehat\\theta := \\dfrac{1}{N}\\sum_{n=1}^N (x_n - S)^2 $$\n",
    "\n",
    "oraz __nieobciążony__ estymator wariancji\n",
    "\n",
    "$$ \\widehat\\theta := \\dfrac{1}{N-1}\\sum_{n=1}^N (x_n - S)^2 $$\n",
    "\n",
    "Estymatory obciążone mają __niezerowy bias__. Estymatory nieobciążone są lepsze. Wrócimy jeszcze do dyskusji na temat estymatorów obciążonych przy okazji omawiania _bias-variance trade off_.\n",
    "\n",
    "### Maximum Likelihood Estimator (MLE)\n",
    "\n",
    "MLE jest, zgodnie z nazwą, estymatorem. Przypomnijmy definicję\n",
    "\n",
    "$$\\widehat\\theta = \\underset{\\theta^k}{\\arg\\max}\\;p\\,(D_{Tr}\\mid\\theta=\\theta^k)$$\n",
    "\n",
    "W tym wypadku $\\theta$ ma być \"prawdziwą\" hipotezą na temat danych."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estymator wartości oczekiwanej - ważna uwaga"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Niech $X$ ma rozkład dyskretny na zbiorze $\\{x^1, \\ldots x^K\\}$, a $y^1, \\ldots, y^N$ będzie ciągiem sampli z tego rozkładu.\n",
    "\n",
    "Wartość oczekiwana $X$ jest zdefiniowana jako\n",
    "\n",
    "$$\\mathbb{E}X := p(X=x^1)\\cdot x^1 + \\ldots + p(X=x^K)\\cdot x^K$$\n",
    "\n",
    "natomiast estymator wartości oczekiwanej to\n",
    "\n",
    "$$ \\widehat\\theta := \\dfrac{1}{N}y^1 + \\ldots + \\dfrac{1}{N}y^N $$\n",
    "\n",
    "#### Pytanie\n",
    "\n",
    "Twierdzimy, że ten estymator jest dobrym przybliżeniem - ale w takim razie dlaczego w drugim przypadku wszystkie wagi są równe $\\dfrac{1}{N}$? Dlaczego np. nie użyć estymatora\n",
    "$$ \\widehat\\theta := p(y^1)\\cdot y^1 + \\ldots + p(y^N)\\cdot y^N $$\n",
    "\n",
    "A jak sprawa wygląda w wypadku rozkładów ciągłych?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
