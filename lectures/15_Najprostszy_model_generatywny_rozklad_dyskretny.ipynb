{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Najprostszy model generatywny - rozkład dyskretny\n",
    "\n",
    "1. rozkład dyskretny na skończonym zbiorze, $K$ możliwych wartości\n",
    "2. dane treningowe\n",
    "$$\\{x_n\\}$$\n",
    "    * $x_n\\in\\{c_1, \\ldots, c_K\\}$\n",
    "    * $c_k$ to mogą być np. liczby rzeczywiste\n",
    "    * może też być np. $c_k := k-1$\n",
    "    * prawdziwy rozkład prawdopodobieństwa oznaczamy $p(x)$\n",
    "3. parametry\n",
    "    * $K$ parametrów może w pełni opisać ten rozkład\n",
    "    * $\\theta = (\\theta_1, \\ldots, \\theta_K) := (\\widehat{p}(x=c_1), \\ldots, \\widehat{p}(x=c_K))$\n",
    "    * $\\widehat{p}(x=c_k)$ to __estymowana przez model__ wartość $p(x=c_k)$\n",
    "    * w takim razie model musi przestrzegać ograniczeń\n",
    "        * $0\\leq\\theta_k\\leq 1$\n",
    "        * $\\sum_{k=1}^K\\theta_k=1$\n",
    "4. likelihood jest wyznaczony (liczbowo) przez $\\widehat{p}$\n",
    "5. niech w zbiorze treningowym będzie $N_k$ elementów równych $c_k$\n",
    "$$N = N_1 + \\ldots + N_K$$\n",
    "6. likelihood zbioru treningowego to\n",
    "$$\\widehat{p}(x=c_1)^{N_1}\\cdot\\ldots\\cdot \\widehat{p}(x=c_K)^{N_K} = \\prod_{k=1}^K\\widehat{p}(x=c_k)^{N_k}$$\n",
    "7. negative mean log likelihood to\n",
    "$$\\begin{align}-(\\dfrac{N_1}{N}\\ln[\\widehat{p}(x=c_1)]+\\cdot+\\dfrac{N_K}{N}\\ln[\\widehat{p}(x=c_K)] )&= -\\sum_{k=1}^K\\dfrac{N_k}{N}\\ln[\\widehat{p}(x=c_k)] \\\\ &= -\\sum_{k=1}^K\\dfrac{N_k}{N}\\ln\\theta_k\\end{align}$$\n",
    "8. gradient\n",
    "$$\\dfrac{\\partial L}{\\partial\\theta_k}(\\theta) = - \\dfrac{\\frac{N_k}{N}}{\\theta_k}$$\n",
    "9. gdzie jest minimum $L$\n",
    "    * jeśli $\\theta_k = \\dfrac{N_k}{N}$, to $\\nabla L = (-1, \\ldots, -1)$\n",
    "    * kierunek najszybszego wzrostu jest prostopadły do przestrzeni, po której możemy się poruszać\n",
    "    * pochodne kierunkowe styczne do dozwolonej przestrzeni są równe zero\n",
    "    * w takim razie minimum to $\\widehat\\theta = (\\dfrac{N_1}{N}, \\ldots, \\dfrac{N_K}{N})$\n",
    "    * model estymuje $\\widehat p$ na podstawie zbioru treningowego\n",
    "        * $\\widehat p(x=c_k) = \\dfrac{N_k}{N}$\n",
    "        * sensowna reguła\n",
    "    * formalnie trzeba udowodnić więcej o $L$, policzyć lagrangian (_constrained optimization_) itd.\n",
    "        * nie będziemy tego robić"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
