{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. zbiór uczący, treningowy\n",
    "    * reprezentuje dane\n",
    "        * zmienne ciągłe (float'y)\n",
    "        * kategorie (int'y)\n",
    "    * funkcja kosztu jako średnia kosztu po wszystkich przykładach\n",
    "\n",
    "\n",
    "2. zbiór testowy\n",
    "    * oddzielnie od zbioru treningowego\n",
    "    * __takie same__, ale nie __te same__ dane\n",
    "    * służy do oceny nauczonego modelu\n",
    "\n",
    "\n",
    "3. __postać__ funkcji kosztu\n",
    "    * __model liniowy__ wypukła, jedno minimum globalne\n",
    "        * __elipsoida__ dla problemów regresji liniowej\n",
    "        * __bardzo wąska__ utrudni\n",
    "        * __normalizacja__ \n",
    "    * __nieliniowe modele__ wiele minimów lokalnych\n",
    "        * __bardzo zróżnicowana__ dla złożonych modeli\n",
    "    * szerokie _plateau_\n",
    "        * niska wartość gradientu\n",
    "        * powolne uczenie\n",
    "\n",
    "\n",
    "4. numeryczne sprawdzanie gradientów\n",
    "    * metody różnicowe\n",
    "    * ważne, jeśli sami piszemy model\n",
    "\n",
    "\n",
    "5. __stochastyczność__ algorytmu\n",
    "    * __Stochastic__ Gradient Descent\n",
    "        * pojedyncze przykłady\n",
    "    * __mini-batch__\n",
    "        * zwykle kilka do kilkadziesiąt przykładów\n",
    "    * __epoka__\n",
    "        * każdy przykład treningowy wzięty dokładnie raz\n",
    "    * niezbędne dla bardzo dużych datasetów\n",
    "        * np. GPU ma ograniczoną RAM\n",
    "    * __szybki__, ale __niedokładny__\n",
    "\n",
    "<img src=\"../ml_figures/Optimizery_Podsumowanie_stochastic_vs_batch_gradient_descent.png\" width=\"80%\">\n",
    "\n",
    "6. Jak w praktyce korzystać z optimizerów\n",
    "    * __mieszanie__ przykładów treningowych\n",
    "        * przykłady brać losowo - wystarczy mieszać po epoce\n",
    "        * przykład z tej samej klasy lub o podobnej wartości _nie_ obok siebie\n",
    "    * __śledzenie__ błędu trenowania i walidacji\n",
    "    * uczyć przez wiele epok\n",
    "    * __eksperymentowanie__ z parametrami optimizera\n",
    "        * mały podzbiór zbioru treningowego\n",
    "        * mniej epok\n",
    "        * wypisywać błąd co minibatch\n",
    "    * __normalizacja__ parametrów początkowych\n",
    "        * w zależności od modelu\n",
    "        * pozwala na wyższe wartości $\\eta$\n",
    "\n",
    "\n",
    "7. warto testować różne optimizery\n",
    "    * RMSprop i Adadelta bardzo podobne\n",
    "    * Adam dodaje lepsze podejście do biasu\n",
    "    * Gradient Descent ma wady, ale też działa\n",
    "\n",
    "\n",
    "8. możliwe modyfikowanie parametrów optimizera w czasie\n",
    "    * _learning rate schedule_\n",
    "        * __duże__\n",
    "            * szybkie ale niestabilne\n",
    "            * może ominąć minimum\n",
    "        * __małe__\n",
    "            * stabilne ale powolne\n",
    "\n",
    "\n",
    "9. __urównoleglenie__ uczenia\n",
    "    * wiele równoległych kopii modelu\n",
    "    * centarlny serwer łączący modyfikacje\n",
    "\n",
    "\n",
    "10. __gradient clipping__\n",
    "    * __gradient explosion problem__\n",
    "    * ręcznie ograniczamy maksymalną normę gradientu"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
